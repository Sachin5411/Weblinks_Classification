{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from flashtext.keyword import KeywordProcessor\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Managing given keywords\n",
    "with open('Interest groups - 5th Sept.txt','r') as f:\n",
    "    c=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0]=c[0][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords=np.array(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(keywords)):\n",
    "    if i == len(keywords)-1:\n",
    "        keywords[i]=keywords[i]\n",
    "    else:\n",
    "        keywords[i]=keywords[i][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads All sites file\n",
    "with open('Quantcast-Top-Million.csv.txt','r') as f:\n",
    "    sites=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weblinks=[]\n",
    "for i in range(6000,7100):\n",
    "    j=sites[i][5:-1]\n",
    "    if j=='Hidden profile':\n",
    "        pass\n",
    "    else:\n",
    "        weblinks.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(weblinks)):\n",
    "    weblinks[i]='https://www.'+weblinks[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.indiamart.com',\n",
       " 'https://www.booksamillion.com',\n",
       " 'https://www.edweek.org',\n",
       " 'https://www.omgsweeps.info',\n",
       " 'https://www.perksatwork.com',\n",
       " 'https://www.twinspires.com',\n",
       " 'https://www.cdkeys.com',\n",
       " 'https://www.ti.com',\n",
       " 'https://www.bjsrestaurants.com',\n",
       " 'https://www.diariogol.com',\n",
       " 'https://www.pearsonrealize.com',\n",
       " 'https://www.consumerlab.com',\n",
       " 'https://www.mandtbank.com',\n",
       " 'https://www.subscene.com',\n",
       " 'https://www.immihelp.com',\n",
       " 'https://www.peoplem.ag',\n",
       " 'https://www.zipjobs.com',\n",
       " 'https://www.premierguitar.com',\n",
       " 'https://www.mrmoneymustache.com',\n",
       " 'https://www.lync.com']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sample\n",
    "weblinks[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving links in database\n",
    "\n",
    "conn= mysql.connector.connect(host='localhost',user='sachin',passwd='mysqlsachin',database='interntask2')\n",
    "\n",
    "mycursor=conn.cursor()\n",
    "\n",
    "mycursor.execute(\"\"\"DROP TABLE IF EXISTS weblink\"\"\")\n",
    "mycursor.execute(\"CREATE TABLE weblinks(weblinks VARCHAR(800))\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "query = \"INSERT INTO randomlinks (weblinks) VALUES (%s)\"\n",
    "mycursor.executemany(query, [(list_item, ) for list_item in weblinks])\n",
    "\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weblinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp0=KeywordProcessor()\n",
    "\n",
    "for word in keywords:\n",
    "    kp0.add_keyword(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from bs4.element import Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_visible(element):\n",
    "    if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
    "        return False\n",
    "    if isinstance(element, Comment):\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gethtmlcontent(url):\n",
    "    try:\n",
    "        soup = BeautifulSoup(url, 'html.parser')  #Parse html code\n",
    "        texts = soup.findAll(text=True)\n",
    "        visible_texts = filter(tag_visible, texts)  \n",
    "        return u\" \".join(t.strip() for t in visible_texts)\n",
    "        \n",
    "    \n",
    "    except Exception as error:\n",
    "        print('Error occured: {}'.format(error))\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw=stopwords.words('english')\n",
    "to_remove=['[]','','1','()','||','=','.',',','\\n',':',';','\\\\','//','/']\n",
    "\n",
    "for i in to_remove:\n",
    "    sw.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_keywords(text):\n",
    "    x=str(text)\n",
    "    \n",
    "    x=x.split(' ')\n",
    "    words=[w for w in x]\n",
    "    sws=set(sw)\n",
    "    useful_words=[w for w in words if w not in sws]\n",
    "    \n",
    "    uniq=np.unique(useful_words,return_counts=True)\n",
    "    \n",
    "    if len(uniq[1])==0:\n",
    "        return 0\n",
    "    else:\n",
    "        index=np.argmax(uniq[1])\n",
    "    \n",
    "    \n",
    "    return uniq[0][index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_class(text_from_html):\n",
    "    x=str(text_from_html)\n",
    "    y0 = len(kp0.extract_keywords(x))\n",
    "    if y0==0:\n",
    "        top_kw=top_keywords(text_from_html)\n",
    "        #Category='None'\n",
    "        return 0,top_kw\n",
    "    \n",
    "    else:\n",
    "        kw=kp0.extract_keywords(x)\n",
    "        uniq_kw=np.unique(kw,return_counts=True)\n",
    "        \n",
    "        m=np.argmax(uniq_kw[1])\n",
    "        max_kw=uniq_kw[1][m]\n",
    "        sum_kw=np.sum(uniq_kw[1])\n",
    "        \n",
    "        return (max_kw/(sum_kw))*100,kw,max_kw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites=['https://palladiumdancecompany.com','https://www.beatport.com/genre/dance/39','https://en.wikipedia.org/wiki/Dance','https://en.wikipedia.org/wiki/Music','https://support.apple.com/music','https://www.theguardian.com/music']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "confidences=[]\n",
    "category=[]\n",
    "links=[]\n",
    "combine=[]\n",
    "for i in range(len(sites)):\n",
    "    url= sites[i]\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Cafari/537.36'}\n",
    "    \n",
    "\n",
    "    try:\n",
    "        page = requests.get(url,headers=headers)  #to extract page from website\n",
    "    except requests.exceptions.ConnectionError:\n",
    "    \n",
    "        i+=1\n",
    "        continue\n",
    "    sc=page.status_code\n",
    "    if sc == 403:\n",
    "        continue\n",
    "    \n",
    "    html_code = page.content      #to extract html code from page\n",
    "    text_from_html=gethtmlcontent(html_code)\n",
    "    #print(text_from_html)\n",
    "    confidence,kw,number_of_time_repeated=find_class(text_from_html)\n",
    "    confidences.append(confidence)\n",
    "    \n",
    "    print(\"Confidience : \",confidence)\n",
    "    uniqkw=np.unique(kw,return_counts=True)\n",
    "    \n",
    "    m=np.argmax(uniqkw[1])\n",
    "    links.append(sites[i])\n",
    "    \n",
    "    print(\"Top_keyword: \",uniqkw[0][m])\n",
    "    \n",
    "    print(\"Link: \",sites[i])\n",
    "    category.append(uniqkw[0][m])\n",
    "    combine.append((sites[i],confidence,uniqkw[0][m]))\n",
    "    print('-'*75)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn= mysql.connector.connect(host='localhost',user='sachin',passwd='mysqlsachin',database='atginterntask2')\n",
    "\n",
    "mycursor=conn.cursor()\n",
    "\n",
    "mycursor.execute(\"\"\"DROP TABLE IF EXISTS web_classification\"\"\")\n",
    "mycursor.execute(\"CREATE TABLE web_classification(weblinks VARCHAR(800),confidence INT(200),kw VARCHAR(600))\")\n",
    "\n",
    "\n",
    "query1 = \"\"\"INSERT INTO  web_classification(weblinks) \n",
    "           VALUES (%s)\"\"\"\n",
    "\n",
    "#mycursor.executemany((query1,), category)\n",
    "mycursor.executemany(query1, [(list_item, ) for list_item in links])\n",
    "# mycursor.executemany((query2,), combined.any())\n",
    "# mycursor.executemany((query3,), combined.any())\n",
    "                     \n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
